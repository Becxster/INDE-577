
# Gradient Boosting

Gradient Boosting is a powerful ensemble machine learning technique used for both **classification** and **regression** tasks. It builds a strong predictive model by combining the outputs of many weak learners, typically decision trees. It works by training each weak learner to minimize the residual error left by the previous learners, which helps the model improve every iteration.

In this notebook, I offer an overview of the fundamentals behind gradient boosting, and use noisy generated data to demonstrate its power. 

## Steps to Run the Code
1. **Clone the Repository**:
    ```sh
    git clone https://github.com/Becxster/INDE-577.git
    cd <repository-directory>
    ```

2. **Install Dependencies**: Ensure you have the required Python packages installed. You can install them using:
    ```sh
    pip install -r requirements.txt
    ```

3. **Open the Jupyter Notebook**: Launch Jupyter Notebook from the command line:
    ```sh
    jupyter notebook
    ```
    Open boosting.ipynb from the Jupyter interface.
4. **Run the Cells**